{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import groq\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "GROQ_API_KEY = os.environ['GROQ_API_KEY']\n",
    "\n",
    "model = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "client = Groq(api_key=GROQ_API_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Formatting model response as JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "   \"books\":[\n",
      "      {\n",
      "         \"title\":\"The Beholders\",\n",
      "         \"author\":\"Hester Musson\"\n",
      "      },\n",
      "      {\n",
      "         \"title\":\"The Mystery Guest\",\n",
      "         \"author\":\"Nita Prose\"\n",
      "      }\n",
      "   ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# You need to specify the model that you want a json response\n",
    "prompt = \"\"\"\n",
    "I have these notes with book titles and authors: New releases this week! The Beholders by Hester Musson, \n",
    "The Mystery Guest by Nita Prose. Please organize the titles and authors in a json file.\n",
    "\"\"\"\n",
    "\n",
    "response = client.chat.completions.create(\n",
    "    model=model,\n",
    "    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "    response_format={\"type\": \"json_object\"}\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 404 - {'error': {'message': 'The model `this is a model that does not exist` does not exist or you do not have access to it.', 'type': 'invalid_request_error', 'code': 'model_not_found'}}\n"
     ]
    }
   ],
   "source": [
    "# - NotFoundError: Model not found\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"this is a model that does not exist\",\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "except groq.NotFoundError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 401 - {'error': {'message': 'Invalid API Key', 'type': 'invalid_request_error', 'code': 'invalid_api_key'}}\n"
     ]
    }
   ],
   "source": [
    "# Connection errors:\n",
    "# - InternalServerError\n",
    "# - APIConectionError\n",
    "# - APITimeoutError\n",
    "# Potential solution: Checking connection config and reaching out to Groq support\n",
    "\n",
    "# - AuthenticationError: Invalid API key\n",
    "client = Groq(api_key=\"this is a fake API key\")\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "except groq.InternalServerError as e:\n",
    "    print(e)\n",
    "except groq.APIConnectionError as e:\n",
    "    print(e)\n",
    "except groq.APITimeoutError as e:\n",
    "    print(e)\n",
    "except groq.AuthenticationError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resource limit errors:\n",
    "# - ConflictError\n",
    "# - RateLimitError\n",
    "# Solutions: Checking limit restrictions and ensure requests are within limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 400 - {'error': {'message': \"'messages.0' : discriminator property 'role' has invalid value\", 'type': 'invalid_request_error'}}\n"
     ]
    }
   ],
   "source": [
    "# Bad requests errors\n",
    "# - BadRequestError\n",
    "\n",
    "client = groq.Groq(api_key=GROQ_API_KEY)\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"not valid role\", \"content\": prompt}],\n",
    "        response_format={\"type\": \"json_object\"}\n",
    "    )\n",
    "except groq.BadRequestError as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are five data science professions:\n",
      "\n",
      "1. **Data Scientist**: A data scientist collects, analyzes, and interprets complex data to gain insights and inform business decisions. They use various techniques such as machine learning, statistical modeling, and data visualization to extract meaningful patterns and trends from data.\n",
      "\n",
      "2. **Data Analyst**: A data analyst works with data to identify trends, create reports, and develop visualizations to help organizations make informed decisions. They use tools like Excel, SQL, and data visualization software to analyze and present data insights.\n",
      "\n",
      "3. **Machine Learning Engineer**: A machine learning engineer designs and develops artificial intelligence and machine learning systems that can learn from data and make predictions or decisions. They use programming languages like Python, R, or Julia to build and deploy machine learning models.\n",
      "\n",
      "4. **Business Intelligence Developer**: A business intelligence developer creates data visualizations, reports, and dashboards to help organizations understand their data and make data-driven decisions. They use tools like Tableau, Power BI, or D3.js to design and develop interactive and dynamic visualizations.\n",
      "\n",
      "5. **Data Architect**: A data architect designs and implements data management systems, including data warehouses, data lakes, and data governance frameworks. They ensure that data is properly stored, processed, and secured, and that it meets the needs of various stakeholders within an organization.\n"
     ]
    }
   ],
   "source": [
    "# Handling the exceptions\n",
    "\n",
    "try:\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[{\"role\": \"user\", \"content\": \"List five data science professions\"}]\n",
    "    )\n",
    "except groq.AuthenticationError as e:\n",
    "    print(f\"Groq API failed to authenticate: {e}\")\n",
    "except groq.NotFoundError as e:\n",
    "    print(f\"Model not found: {e}\")\n",
    "except groq.RateLimitError as e:\n",
    "    print(f\"Groq API rate limit exceeded: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unable to generate response. Error: {e}\")\n",
    "finally:\n",
    "    print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Here are five data science professions:\\n\\n1. **Data Scientist**: A data scientist collects, analyzes, and interprets complex data to gain insights and make informed decisions. They use various techniques, including machine learning, statistical modeling, and data visualization.\\n\\n2. **Data Engineer**: A data engineer designs, builds, and maintains large-scale data systems, including data pipelines, architectures, and warehouses. They ensure that data is properly stored, processed, and retrieved.\\n\\n3. **Business Intelligence Analyst**: A business intelligence analyst uses data analytics and visualization tools to help organizations make data-driven decisions. They create reports, dashboards, and data visualizations to communicate insights to stakeholders.\\n\\n4. **Machine Learning Engineer**: A machine learning engineer develops and deploys machine learning models into production environments. They work on designing, training, and optimizing models to solve complex problems and improve system performance.\\n\\n5. **Data Analyst**: A data analyst collects, organizes, and analyzes data to identify trends, create reports, and inform business decisions. They use statistical techniques and data visualization tools to communicate insights to stakeholders and drive business outcomes.'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can retry if the request fails with tenacity package\n",
    "# - stop_after_attempt: stops after a certain number of attempts\n",
    "# - wait_random_exponential: waits for a random amount of time between attempts\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "\n",
    "@retry(stop=stop_after_attempt(3), wait=wait_random_exponential(min=5, max=10))\n",
    "def get_response(model, message):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=[message]\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "get_response(model, {\"role\": \"user\", \"content\": \"List five data science professions\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To convert kilometers to miles, we'll use the conversion factor: 1 kilometer = 0.621371 miles.\n",
      "\n",
      "Here are the conversions:\n",
      "\n",
      "* 5.2 kilometers = 5.2 * 0.621371 ≈ 3.23 miles\n",
      "* 6.3 kilometers = 6.3 * 0.621371 ≈ 3.92 miles\n",
      "* 3.7 kilometers = 3.7 * 0.621371 ≈ 2.30 miles\n",
      "\n",
      "Here is the table with the measurements:\n",
      "\n",
      "| Kilometers | Miles |\n",
      "| --- | --- |\n",
      "| 5.2 | 3.23 |\n",
      "| 6.3 | 3.92 |\n",
      "| 3.7 | 2.30 |\n"
     ]
    }
   ],
   "source": [
    "# Batching referrers to sending multiple requests in a single call\n",
    "# It is useful when you have multiple requests to make and you want to optimize the number of API calls\n",
    "\n",
    "def get_response(messages):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content\n",
    "\n",
    "measurements = [5.2, 6.3, 3.7]\n",
    "messages = []\n",
    "messages.append({\n",
    "    \"role\": \"system\", \n",
    "    \"content\": \"Your task is to convert each measure in kilometers to miles. Your output should be a table with all the measurements.\"\n",
    "})\n",
    "[messages.append({\"role\": \"user\", \"content\": str(i)}) for i in measurements]\n",
    "\n",
    "response = get_response(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting token limits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can set token limits to control the number of requests made\n",
    "# For that you can use tiktoken package\n",
    "# tiktoken solo funciona para modelos de OpenAI\n",
    "# import tiktoken\n",
    "\n",
    "# input_message = {\n",
    "#     \"role\": \"user\", \n",
    "#     \"content\": \"I'd like to buy a shirt and a jacket. Can you suggest two color pairings for these items?\"\n",
    "# }\n",
    "\n",
    "# encoding = tiktoken.encoding_for_model(model)\n",
    "# num_tokens = len(encoding.encode(input_message[\"content\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Al parecer para usar modelos llama en huggingface\n",
    "# se necesita pedir permiso dentro de HF en https://huggingface.co/meta-llama/Llama-3.3-70b-Instruct\n",
    "# Luego de obtener el permiso se tiene que:\n",
    "# - Crear un access token de HF en settings (https://huggingface.co/settings/tokens)\n",
    "# - Correr el siguiente comando: huggingface-cli login\n",
    "# - Copiar y pegar el token y listo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_tokens: 23\n",
      "I can suggest two color pairings for a shirt and a jacket:\n",
      "\n",
      "1. **Neutral combination**: Pair a light-blue shirt with a beige or tan jacket. This classic combination is versatile and suitable for casual or semi-formal events. The light blue adds a touch of calmness, while the beige or tan jacket adds warmth and a natural look.\n",
      "\n",
      "2. **Contrasting combination**: Combine a white or pale-yellow shirt with a navy-blue jacket. This pairing creates a striking contrast that's perfect for making a statement. The white or pale-yellow shirt provides a clean and crisp base, while the navy-blue jacket adds a sense of sophistication and elegance.\n",
      "\n",
      "Remember, these are just suggestions. Ultimately, the color pairing will depend on your personal style, the occasion, and your preferences.\n"
     ]
    }
   ],
   "source": [
    "# En vez de tiktoken, podemos usar transformers de huggingface\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "input_message = {\n",
    "    \"role\": \"user\", \n",
    "    \"content\": \"I'd like to buy a shirt and a jacket. Can you suggest two color pairings for these items?\"\n",
    "}\n",
    "\n",
    "model_id = \"meta-llama/Llama-3.3-70b-Instruct\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "tokens = tokenizer.encode(input_message[\"content\"], return_tensors=\"pt\")\n",
    "\n",
    "num_tokens = len(tokens[0])\n",
    "\n",
    "print(\"num_tokens:\", num_tokens)\n",
    "\n",
    "if num_tokens <= 100:\n",
    "    response = client.chat.completions.create(model=model, messages=[input_message])\n",
    "    print(response.choices[0].message.content)\n",
    "else:\n",
    "    print(\"Message exceeds token limit\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
